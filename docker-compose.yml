# docker-compose.yml

services:
  ollama:
    image: ollama/ollama:latest
    ports:
      - "11434:11434"
    runtime: nvidia
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    volumes:
      - ollama_data:/root/.ollama
    environment:
      - OLLAMA_MODELS=/root/.ollama/models
    entrypoint: /bin/sh -c "ollama serve & sleep 5 && ollama pull llama3.1:8b-instruct-q4_K_M && wait"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:11434/api/tags"]
      interval: 30s
      timeout: 10s
      retries: 3

  chromadb:
    image: chromadb/chroma:latest
    ports:
      - "8000:8000"
    volumes:
      - chroma_data:/chroma/chroma
    environment:
      - ANONYMIZED_TELEMETRY=False
      - ALLOW_RESET=True
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/api/v2/heartbeat"]
      interval: 30s
      timeout: 10s
      retries: 3

  mcp-resume:
    image: ${DOCKER_USERNAME:-thornton}/resume-narrator-mcp:latest
    build:
      context: .
      dockerfile: Dockerfile.mcp
    ports:
      - "9001:9001"
    environment:
      - CHROMA_HOST=http://chromadb:8000
      - OLLAMA_HOST=http://ollama:11434
    volumes:
      - ./data:/app/data
      - ./mcp-servers:/app/mcp-servers
      - .:/app/codebase:ro
    depends_on:
      - chromadb
      - ollama
    command: python /app/mcp-servers/resume_http_server.py
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9001/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  init-vector-db:
    image: ${DOCKER_USERNAME:-thornton}/resume-narrator-mcp:latest
    build:
      context: .
      dockerfile: Dockerfile.mcp
    environment:
      - PYTHONUNBUFFERED=1
    volumes:
      - ./data:/app/data
      - ./scripts:/app/scripts
    depends_on:
      chromadb:
        condition: service_healthy
      ollama:
        condition: service_healthy
    command: python /app/scripts/init_vector_db.py
    restart: "no"
    profiles:
      - init

  mcp-vector:
    image: ${DOCKER_USERNAME:-thornton}/resume-narrator-mcp:latest
    build:
      context: .
      dockerfile: Dockerfile.mcp
    ports:
      - "9002:9002"
    environment:
      - CHROMA_HOST=http://chromadb:8000
      - OLLAMA_HOST=http://ollama:11434
    volumes:
      - ./data:/app/data
      - ./mcp-servers:/app/mcp-servers
      - .:/app/codebase:ro
    depends_on:
      - chromadb
      - ollama
    command: python /app/mcp-servers/vector_http_server.py
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9002/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  mcp-code:
    image: ${DOCKER_USERNAME:-thornton}/resume-narrator-mcp:latest
    build:
      context: .
      dockerfile: Dockerfile.mcp
    ports:
      - "9003:9003"
    environment:
      - CHROMA_HOST=http://chromadb:8000
      - OLLAMA_HOST=http://ollama:11434
    volumes:
      - ./data:/app/data
      - ./mcp-servers:/app/mcp-servers
      - .:/app/codebase:ro
    depends_on:
      - chromadb
      - ollama
    command: python /app/mcp-servers/code_http_server.py
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9003/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  agent:
    image: ${DOCKER_USERNAME:-thornton}/resume-narrator-agent:latest
    build:
      context: .
      dockerfile: Dockerfile.agent
    ports:
      - "8080:8080"
    environment:
      - OLLAMA_HOST=http://ollama:11434
      - OLLAMA_MODEL=llama3.1:8b-instruct-q4_K_M
      - CHROMA_HOST=http://chromadb:8000
      - MCP_RESUME_URL=http://mcp-resume:9001
      - MCP_VECTOR_URL=http://mcp-vector:9002
      - MCP_CODE_URL=http://mcp-code:9003
    volumes:
      - ./data:/app/data
      - ./agent:/app/agent
    depends_on:
      - mcp-resume
      - mcp-vector
      - mcp-code
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Optional: Monitoring stack (enable with: docker compose --profile monitoring up)
  prometheus:
    image: prom/prometheus:latest
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
    profiles:
      - monitoring

  grafana:
    image: grafana/grafana:latest
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASSWORD:-admin}
      - GF_INSTALL_PLUGINS=redis-datasource
    volumes:
      - grafana_data:/var/lib/grafana
      - ./monitoring/grafana/dashboards:/etc/grafana/provisioning/dashboards
      - ./monitoring/grafana/datasources:/etc/grafana/provisioning/datasources
    profiles:
      - monitoring
    depends_on:
      - prometheus

  autoupdater:
    build: ./auto-updater
    ports:
      - "8008:8008"
    restart: always
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - /home/ross/project/resume-narrator/:/host/project
    # Run as root to ensure Docker socket access
    # (alternative: get host docker group GID via: stat -c '%g' /var/run/docker.sock)
    user: "0"
    environment:
      - PROJECT_DIR=/host/project
      - DOCKER_HOST=unix:///var/run/docker.sock
    command: python webhook_listener.py

volumes:
  ollama_data:
  chroma_data:
  prometheus_data:
  grafana_data:
